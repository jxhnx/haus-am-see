# Resolve JVM deps (Iceberg, Hadoop/AWS, Avro)
FROM maven:3-eclipse-temurin-24 AS deps
WORKDIR /build
COPY compose/spark/pom.xml .
RUN mvn -q -DoutputDirectory=target/jars dependency:copy-dependencies

# Spark runtime
FROM spark:3.5.6-scala2.12-java17-python3-ubuntu

USER root

# Install Python 3.11 venv
RUN set -eux; \
    apt update; \
    apt install -y --no-install-recommends software-properties-common ca-certificates; \
    add-apt-repository -y ppa:deadsnakes/ppa; \
    apt update; \
    apt install -y --no-install-recommends python3.11 python3.11-venv; \
    python3.11 -m venv /opt/venv; \
    /opt/venv/bin/python -m ensurepip --upgrade; \
    /opt/venv/bin/python -m pip install --no-cache-dir --upgrade pip setuptools wheel; \
    rm -rf /var/lib/apt/lists/*

ENV PATH=/opt/venv/bin:$PATH \
    PYSPARK_PYTHON=/opt/venv/bin/python \
    PYSPARK_DRIVER_PYTHON=/opt/venv/bin/python

# Workspace layout
WORKDIR /home/spark
RUN mkdir -p \
      /home/spark/work \
      /opt/spark/jars

RUN chown -R spark:spark /home/spark

# JVM deps
COPY --from=deps /build/target/jars/ /opt/spark/jars/

# Python deps
COPY compose/spark/requirements.txt /tmp/requirements.txt
RUN /opt/venv/bin/python -m pip install --no-cache-dir -r /tmp/requirements.txt \
 && /opt/venv/bin/python -m pip check \
 && rm /tmp/requirements.txt

USER spark
ENV PYTHONPATH="/home/spark/work"
